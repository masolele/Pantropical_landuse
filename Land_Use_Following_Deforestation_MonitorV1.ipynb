{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHzOEaWRps0z"
   },
   "source": [
    "üåç POST-DEFORESTATION LAND USE PREDICTION SYSTEM\n",
    "===========================================\n",
    "\n",
    "Author: Robert Masolele, Wageningen University\n",
    "\n",
    "Date: 2025\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "OVERVIEW:\n",
    "---------\n",
    "This notebook provides an interactive tool for predicting land use following\n",
    "deforestation using region-specific deep learning models trained on Sentinel-1,\n",
    "Sentinel-2, and location encoding data.\n",
    "\n",
    "Before we start, please have your GEE cloud project id with you. In the next cell STEP:1, You will need it to initialize Google Earth Engine (GEE)\n",
    "\n",
    "FEATURES:\n",
    "---------\n",
    "All the cells contain functions, except the last cell. Run all the cells, and on the output of the last cell follow the steps below by clicking the icons on the right. I advise to draw a small area i.e. <10 km square to get results fast. I f you get error check STEP 12. TROUBLESHOOTING, otherwise createan issue on my github page.\n",
     "\n",
    "üñºÔ∏è Draw or upload a Region of Interest (ROI) on an interactive map\n",
    "\n",
    "üß† Automatically selects AI model based on location (Africa, Southeast Asia, Latin America)\n",
    "\n",
    "üõ∞Ô∏è Downloads and preprocesses Sentinel-1 + Sentinel-2 + elevation + indices\n",
    "\n",
    "üåæ Predicts land use categories over deforested areas only using ONNX models\n",
    "\n",
    "üó∫Ô∏è Click to visualise side-by-side map of RGB imagery + follow-up land use prediction\n",
    "\n",
    "üì§ You can also export predictions as GeoTIFF for GIS analysis,. Please follow the steps,  cheers!:smili_face_with_heart_eyes \n",
    "\n",
    "SUPPORTED REGIONS:\n",
    "------------------\n",
    "1. AFRICA: 17 input bands, 25 output classes\n",
    "2. SOUTHEAST ASIA: 15 input bands, 24 output classes\n",
    "3. LATIN AMERICA: 15 input bands, 22 output classes\n",
    "\n",
    "WORKFLOW:\n",
    "---------\n",
    "1. Draw ROI on map ‚Üí 2. Download data ‚Üí 3. Run prediction ‚Üí 4. Visualize results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fdx9BFJ8tRnH"
   },
   "source": [
    "# ##1. INSTALLATION AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdtgv9bksAt3",
    "outputId": "94d4bd72-5ced-4d19-cb51-ada8bfd92409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/17.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.6/17.4 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/17.4 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.5/17.4 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m146.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m146.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hüîê Earth Engine authentication required...\n",
      "‚úÖ Installation complete!\n"
     ]
    }
   ],
   "source": [
    "## Run this cell once to install all required packages.\n",
    "\n",
    "# Install required packages\n",
    "!pip install earthengine-api geemap rasterio numpy matplotlib ipywidgets onnxruntime requests folium pyproj tqdm -q\n",
    "\n",
    "# Authenticate Earth Engine\n",
    "import ee\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    print(\"üîê Earth Engine authentication required...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project='ENTER YOUR GEE PROJECT ID')\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5Qt66r_tu8w"
   },
   "source": [
    "# ##2. IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "QfS-O4rZt8sT",
    "outputId": "cc1dd16a-1862-4742-98df-8e3a6a62d2a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.plot import reshape_as_image\n",
    "import cv2\n",
    "import math\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Earth Engine and Geemap\n",
    "import ee\n",
    "import geemap\n",
    "from ipywidgets import widgets, HBox, VBox, Layout, Button, Output, Dropdown\n",
    "from IPython.display import display, clear_output, HTML, FileLink\n",
    "\n",
    "# ONNX Runtime\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Hugging Face\n",
    "import requests\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Coordinate transformation\n",
    "from pyproj import Transformer\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXUhQNfuuETD"
   },
   "source": [
    "# ##3. CONFIGURATION AND CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "b4cKlcjXuRdY",
    "outputId": "82730533-be4a-47cd-e9f9-b85f66548c56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded!\n"
     ]
    }
   ],
   "source": [
    "# Region configurations\n",
    "REGION_CONFIGS = {\n",
    "    'Africa': {\n",
    "        'model_name': 'best_weights_att_unet_lagtime_5_Fused3_2023_totalLoss6V1_without_loss_sentAfrica6.onnx',\n",
    "        'input_bands': 17,\n",
    "        'output_classes': 25,\n",
    "        'classes': [\n",
    "            'Background', 'OLSCP', 'Pasture', 'Mining',\n",
    "            'OSSCP', 'Roads', 'Forest', 'Plantation_forest',\n",
    "            'Coffee', 'Build_up', 'Water', 'Oil_palm', 'Rubber', 'Cocoa',\n",
    "            'Avocado', 'Soy', 'Sugar', 'Maize', 'Banana', 'Pineapple',\n",
    "            'Rice', 'Wood_logging', 'Cashew', 'Tea', 'Others'\n",
    "        ],\n",
    "        'bbox': ee.Geometry.Rectangle([-20.0, -35.0, 55.0, 40.0]),\n",
    "        'color_map': plt.cm.tab20\n",
    "    },\n",
    "    'Southeast Asia': {\n",
    "        'model_name': 'best_weights_att_unet_lagtime_5_Fused3_2023_totalLoss6V1_without_loss_sent_Southeast_Asia23.onnx',\n",
    "        'input_bands': 15,\n",
    "        'output_classes': 24,\n",
    "        'classes': [\n",
    "            'Background', 'OLSCP', 'Pasture', 'Mining',\n",
    "            'OSSCP', 'Roads', 'Forest', 'Plantation_forest',\n",
    "            'Coffee', 'Build_up', 'Water', 'Oil_palm', 'Rubber', 'Cocoa',\n",
    "            'Clove', 'Soy', 'Sugar', 'Maize', 'Banana', 'Pineapple',\n",
    "            'Rice', 'Wood_logging', 'Cashew', 'Tea'\n",
    "        ],\n",
    "        'bbox': ee.Geometry.Rectangle([55.0, -10.0, 150.0, 60.0]),\n",
    "        'color_map': plt.cm.tab20\n",
    "    },\n",
    "    'Latin America': {\n",
    "        'model_name': 'best_weights_att_unet_lagtime_5_Fused3_2023_totalLoss6V1_without_loss_sent_Latin_America56.onnx',\n",
    "        'input_bands': 15,\n",
    "        'output_classes': 22,\n",
    "        'classes': [\n",
    "            'Background', 'OLSCP', 'Pasture', 'Mining',\n",
    "            'OSSCP', 'Roads', 'Forest', 'Plantation_forest',\n",
    "            'Coffee', 'Build_up', 'Water', 'Oil_palm', 'Rubber', 'Cocoa',\n",
    "            'Avocado', 'Soy', 'Sugar', 'Maize', 'Banana', 'Pineapple',\n",
    "            'Rice', 'Wood_logging'\n",
    "        ],\n",
    "        'bbox': ee.Geometry.Rectangle([-95.0, -55.0, -30.0, 20.0]),\n",
    "        'color_map': plt.cm.tab20\n",
    "    }\n",
    "}\n",
    "\n",
    "# Model parameters\n",
    "PATCH_SIZE = 64\n",
    "\n",
    "# Sentinel-2 bands (Harmonized Surface Reflectance)\n",
    "S2_BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12']\n",
    "S1_BANDS = ['VV', 'VH']\n",
    "\n",
    "# Dates for compositing (adjust based on your needs)\n",
    "START_DATE = '2024-01-01'\n",
    "END_DATE = '2024-12-31'\n",
    "\n",
    "# Output directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('downloads', exist_ok=True)\n",
    "os.makedirs('predictions', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Configuration loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmYcEsjJuWUF"
   },
   "source": [
    "# ##4. HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "4m2zMuOPuhZt",
    "outputId": "47562272-fe32-42e4-bbcb-da975a8dd3bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_onnx_model(region_name, cache_dir=\"models\"):\n",
    "    \"\"\"\n",
    "    Load ONNX model for a given region from Hugging Face.\n",
    "\n",
    "    Args:\n",
    "        region_name (str): Region name ('Africa', 'Southeast Asia', 'Latin America')\n",
    "        cache_dir (str): Directory to cache downloaded models\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ort.InferenceSession, dict) Loaded ONNX model session and config\n",
    "    \"\"\"\n",
    "    print(f\"üì• Loading model for region: {region_name}\")\n",
    "\n",
    "    if region_name not in REGION_CONFIGS:\n",
    "        raise ValueError(f\"Unknown region: {region_name}. Choose from {list(REGION_CONFIGS.keys())}\")\n",
    "\n",
    "    config = REGION_CONFIGS[region_name].copy()\n",
    "    filename = config.get('model_name')\n",
    "\n",
    "    if not filename:\n",
    "        raise ValueError(f\"No model filename specified for region: {region_name}\")\n",
    "\n",
    "    print(f\"Model filename: {filename}\")\n",
    "\n",
    "    # Ensure cache directory exists\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    model_path = os.path.join(cache_dir, filename)\n",
    "\n",
    "    # Try multiple sources for the model\n",
    "    model_loaded = False\n",
    "\n",
    "    # Source 1: Check if already downloaded\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"‚úì Found model locally at: {model_path}\")\n",
    "        model_loaded = True\n",
    "\n",
    "    # Source 2: Try Hugging Face\n",
    "    if not model_loaded:\n",
    "        try:\n",
    "            print(f\"Attempting to download from Hugging Face...\")\n",
    "            model_path = hf_hub_download(\n",
    "                repo_id=\"Masolele/deforestwatch-models\",\n",
    "                filename=filename,\n",
    "                repo_type=\"dataset\",\n",
    "                cache_dir=cache_dir,\n",
    "                force_download=True\n",
    "            )\n",
    "            print(f\"‚úì Downloaded from Hugging Face to: {model_path}\")\n",
    "            model_loaded = True\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download from Hugging Face: {e}\")\n",
    "\n",
    "    # Source 3: Try direct URL\n",
    "    if not model_loaded:\n",
    "        try:\n",
    "            print(f\"Attempting direct download...\")\n",
    "            url = f\"https://huggingface.co/datasets/Masolele/deforestwatch-models/resolve/main/{filename}\"\n",
    "            response = requests.get(url, stream=True, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                with open(model_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                print(f\"‚úì Downloaded from direct URL to: {model_path}\")\n",
    "                model_loaded = True\n",
    "        except Exception as e:\n",
    "            print(f\"Direct download failed: {e}\")\n",
    "\n",
    "    if not model_loaded:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find or download model {filename}. \"\n",
    "            f\"Please download it manually from: \"\n",
    "            f\"https://huggingface.co/datasets/Masolele/deforestwatch-models/tree/main\"\n",
    "        )\n",
    "\n",
    "    # Create ONNX Runtime session\n",
    "    print(f\"Creating ONNX Runtime session...\")\n",
    "    session_options = ort.SessionOptions()\n",
    "    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "    # Try to use GPU if available\n",
    "    providers = []\n",
    "    if 'CUDAExecutionProvider' in ort.get_available_providers():\n",
    "        providers.append('CUDAExecutionProvider')\n",
    "        print(\"‚úì CUDA available for GPU acceleration\")\n",
    "    providers.append('CPUExecutionProvider')\n",
    "\n",
    "    try:\n",
    "        model_session = ort.InferenceSession(\n",
    "            model_path,\n",
    "            session_options,\n",
    "            providers=providers\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating session: {e}\")\n",
    "        print(\"Falling back to CPU only...\")\n",
    "        model_session = ort.InferenceSession(\n",
    "            model_path,\n",
    "            session_options,\n",
    "            providers=['CPUExecutionProvider']\n",
    "        )\n",
    "\n",
    "    # Get model info\n",
    "    input_info = model_session.get_inputs()[0]\n",
    "    output_info = model_session.get_outputs()[0]\n",
    "\n",
    "    print(f\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"   Input shape: {input_info.shape}\")\n",
    "    print(f\"   Output shape: {output_info.shape}\")\n",
    "\n",
    "    # Update config with model info\n",
    "    config['actual_input_shape'] = input_info.shape\n",
    "    config['actual_output_shape'] = output_info.shape\n",
    "    config['model_path'] = model_path\n",
    "\n",
    "    return model_session, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNj8s0OYvEgJ"
   },
   "source": [
    "# ## 5. PREPROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eDsS2jsOvWS3",
    "outputId": "6c89e065-492d-4748-dcdd-6619c579e1ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Normalization functions\n",
    "def normalise_vv(raster):\n",
    "    \"\"\"Normalize VV band (-25 to 0 dB)\"\"\"\n",
    "    raster = np.clip(raster, -25, 0)\n",
    "    return (raster + 25) / 25\n",
    "\n",
    "def normalise_vh(raster):\n",
    "    \"\"\"Normalize VH band (-30 to -5 dB)\"\"\"\n",
    "    raster = np.clip(raster, -30, -5)\n",
    "    return (raster + 30) / 25\n",
    "\n",
    "def normalise_longitude(raster):\n",
    "    \"\"\"Normalize longitude values (-180 to 180)\"\"\"\n",
    "    raster = np.clip(raster, -180, 180)\n",
    "    return (raster + 180) / 360\n",
    "\n",
    "def normalise_latitude(raster):\n",
    "    \"\"\"Normalize latitude values (-60 to 60)\"\"\"\n",
    "    raster = np.clip(raster, -60, 60)\n",
    "    return (raster + 60) / 120\n",
    "\n",
    "def normalise_altitude(raster):\n",
    "    \"\"\"Normalize elevation values (-400 to 8000 m)\"\"\"\n",
    "    raster = np.clip(raster, -400, 8000)\n",
    "    return (raster + 400) / 8400\n",
    "\n",
    "def normalise_ndre(raster):\n",
    "    \"\"\"Normalize NDRE values (-1 to 1)\"\"\"\n",
    "    raster = np.clip(raster, -1, 1)\n",
    "    return (raster + 1) / 2\n",
    "\n",
    "def normalise_evi(raster):\n",
    "    \"\"\"Normalize EVI values (-1 to 1)\"\"\"\n",
    "    raster = np.clip(raster, -1, 1)\n",
    "    return (raster + 1) / 2\n",
    "\n",
    "def normalise_ndvi(raster):\n",
    "    \"\"\"Normalize NDVI values (-1 to 1)\"\"\"\n",
    "    raster = np.clip(raster, -1, 1)\n",
    "    return (raster + 1) / 2\n",
    "\n",
    "def norm_optical(image):\n",
    "    \"\"\"\n",
    "    Normalize optical bands using log-sigmoid transformation.\n",
    "    \"\"\"\n",
    "    NORM_PERCENTILES = np.array([\n",
    "        [1.7417, 2.0233], [1.7261, 2.0389], [1.6798, 2.1796],\n",
    "        [2.3829, 2.7578], [1.7417, 2.0233], [1.7417, 2.0233],\n",
    "        [1.7417, 2.0233], [1.7417, 2.0233], [1.7417, 2.0233]\n",
    "    ])\n",
    "\n",
    "    image = np.log(image * 0.005 + 1)\n",
    "    image = (image - NORM_PERCENTILES[:, 0]) / NORM_PERCENTILES[:, 1]\n",
    "    image = np.exp(image * 5 - 1)\n",
    "    image = image / (image + 1)\n",
    "    return image\n",
    "\n",
    "def extract_lat_lon(image_path):\n",
    "    \"\"\"\n",
    "    Extract latitude and longitude values for each pixel.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the georeferenced image\n",
    "\n",
    "    Returns:\n",
    "        tuple: (latitudes, longitudes) arrays\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with rasterio.open(image_path) as src:\n",
    "            transform = src.transform\n",
    "            crs = src.crs\n",
    "            height, width = src.shape\n",
    "\n",
    "            rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
    "            xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
    "            xs = np.array(xs)\n",
    "            ys = np.array(ys)\n",
    "\n",
    "            if crs.to_string() != \"EPSG:4326\":\n",
    "                transformer = Transformer.from_crs(crs, \"EPSG:4326\", always_xy=True)\n",
    "                longitudes, latitudes = transformer.transform(xs, ys)\n",
    "            else:\n",
    "                longitudes, latitudes = xs, ys\n",
    "\n",
    "            return latitudes, longitudes\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not extract lat/lon from {image_path}: {e}\")\n",
    "        # Return dummy coordinates\n",
    "        height, width = 100, 100\n",
    "        lon = np.linspace(-180, 180, width)\n",
    "        lat = np.linspace(-90, 90, height)\n",
    "        lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "        return lat_grid, lon_grid\n",
    "\n",
    "def preprocess_africa(x_img, image_path=None, transform=None, crs=None):\n",
    "    \"\"\"\n",
    "    Preprocess image for Africa model (17 bands).\n",
    "\n",
    "    Args:\n",
    "        x_img: Input image array (H, W, C)\n",
    "        image_path: Path to image file (optional)\n",
    "        transform: Geotransform (optional)\n",
    "        crs: Coordinate reference system (optional)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed image (H, W, 17)\n",
    "    \"\"\"\n",
    "    # Extract optical bands (0-8)\n",
    "    optical = x_img[:, :, :9].astype(np.float32)\n",
    "    optical = np.where(optical < 0, 0, optical)\n",
    "    optical_norm = norm_optical(optical)\n",
    "\n",
    "    # SAR bands (9-10)\n",
    "    vv = normalise_vv(x_img[:, :, 9].astype(np.float32))\n",
    "    vh = normalise_vh(x_img[:, :, 10].astype(np.float32))\n",
    "\n",
    "    # Elevation (11)\n",
    "    alt = normalise_altitude(x_img[:, :, 11].astype(np.float32))\n",
    "\n",
    "    # Coordinates\n",
    "    if transform is not None and crs is not None:\n",
    "        height, width = x_img.shape[:2]\n",
    "        rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
    "        xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
    "\n",
    "        # Convert to 2D arrays\n",
    "        xs = np.array(xs).reshape(height, width)\n",
    "        ys = np.array(ys).reshape(height, width)\n",
    "\n",
    "        if crs.to_string() != \"EPSG:4326\":\n",
    "            transformer = Transformer.from_crs(crs, \"EPSG:4326\", always_xy=True)\n",
    "            longitudes, latitudes = transformer.transform(xs, ys)\n",
    "        else:\n",
    "            longitudes, latitudes = xs, ys\n",
    "\n",
    "        lon_norm = normalise_longitude(longitudes)\n",
    "        lat_norm = normalise_latitude(latitudes)\n",
    "\n",
    "    # Vegetation indices\n",
    "    red_edge1 = optical[:, :, 3]\n",
    "    nir = optical[:, :, 6]\n",
    "    red = optical[:, :, 2]\n",
    "    blue = optical[:, :, 0]\n",
    "\n",
    "    ndvi = np.where((nir + red) == 0, 0, (nir - red) / (nir + red))\n",
    "    evi = np.where((nir + red) == 0, 0, 2.5 * ((nir - red) / (nir + 6 * red - 7.5 * blue + 1)))\n",
    "    ndre = np.where((nir + red_edge1) == 0, 0, (nir - red_edge1) / (nir + red_edge1))\n",
    "\n",
    "    evi_norm = normalise_evi(evi)\n",
    "    ndre_norm = normalise_ndre(ndre)\n",
    "\n",
    "    # Ensure 3D shape\n",
    "    ndvi = ndvi[:, :, np.newaxis] if ndvi.ndim == 2 else ndvi\n",
    "    evi_norm = evi_norm[:, :, np.newaxis] if evi_norm.ndim == 2 else evi_norm\n",
    "    ndre_norm = ndre_norm[:, :, np.newaxis] if ndre_norm.ndim == 2 else ndre_norm\n",
    "    vv = vv[:, :, np.newaxis] if vv.ndim == 2 else vv\n",
    "    vh = vh[:, :, np.newaxis] if vh.ndim == 2 else vh\n",
    "    alt = alt[:, :, np.newaxis] if alt.ndim == 2 else alt\n",
    "    #lon_norm = lon_norm[:, :, np.newaxis] if lon_norm.ndim == 2 else lon_norm\n",
    "    #lat_norm = lat_norm[:, :, np.newaxis] if lat_norm.ndim == 2 else lat_norm\n",
    "\n",
    "    # For Debugging: Print shapes before concatenation\n",
    "    print(f\"lon_norm shape: {lon_norm.shape}, ndim: {lon_norm.ndim}\")\n",
    "    print(f\"lat_norm shape: {lat_norm.shape}, ndim: {lat_norm.ndim}\")\n",
    "\n",
    "    # Force reshape to 3D if needed\n",
    "    h, w = x_img.shape[:2]\n",
    "    if lon_norm.ndim != 3:\n",
    "        lon_norm = lon_norm.reshape(h, w, 1)\n",
    "    if lat_norm.ndim != 3:\n",
    "        lat_norm = lat_norm.reshape(h, w, 1)\n",
    "\n",
    "    # Concatenate all bands\n",
    "    image = np.concatenate([\n",
    "        optical_norm,      # 9\n",
    "        ndvi,              # 1\n",
    "        ndre_norm,         # 1\n",
    "        evi_norm,          # 1\n",
    "        vv,                # 1\n",
    "        vh,                # 1\n",
    "        alt,               # 1\n",
    "        lon_norm,          # 1\n",
    "        lat_norm           # 1\n",
    "    ], axis=2)  # Total: 17 bands\n",
    "\n",
    "    # Ensure correct number of bands\n",
    "    if image.shape[2] != 17:\n",
    "        if image.shape[2] < 17:\n",
    "            padding = np.zeros((image.shape[0], image.shape[1], 17 - image.shape[2]))\n",
    "            image = np.concatenate([image, padding], axis=2)\n",
    "        else:\n",
    "            image = image[:, :, :17]\n",
    "\n",
    "    return np.nan_to_num(image, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "def preprocess_latin_america(x_img, image_path=None, transform=None, crs=None):\n",
    "    \"\"\"\n",
    "    Preprocess image for Latin America model (15 bands).\n",
    "    \"\"\"\n",
    "    # Extract optical bands\n",
    "    optical = x_img[:, :, :9].astype(np.float32)\n",
    "    optical = np.where(optical < 0, 0, optical)\n",
    "    optical_norm = norm_optical(optical)\n",
    "\n",
    "    # SAR bands\n",
    "    vv = normalise_vv(x_img[:, :, 9].astype(np.float32))\n",
    "    vh = normalise_vh(x_img[:, :, 10].astype(np.float32))\n",
    "\n",
    "    # Elevation\n",
    "    alt = normalise_altitude(x_img[:, :, 11].astype(np.float32))\n",
    "\n",
    "    # Coordinates\n",
    "    if transform is not None and crs is not None:\n",
    "        height, width = x_img.shape[:2]\n",
    "        rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
    "        xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
    "\n",
    "        # Convert to 2D arrays\n",
    "        xs = np.array(xs).reshape(height, width)\n",
    "        ys = np.array(ys).reshape(height, width)\n",
    "\n",
    "        if crs.to_string() != \"EPSG:4326\":\n",
    "            transformer = Transformer.from_crs(crs, \"EPSG:4326\", always_xy=True)\n",
    "            longitudes, latitudes = transformer.transform(xs, ys)\n",
    "        else:\n",
    "            longitudes, latitudes = xs, ys\n",
    "\n",
    "        lon_norm = normalise_longitude(longitudes)\n",
    "        lat_norm = normalise_latitude(latitudes)\n",
    "\n",
    "    # NDVI only\n",
    "    nir = optical[:, :, 6]\n",
    "    red = optical[:, :, 2]\n",
    "    ndvi = np.where((nir + red) == 0, 0, (nir - red) / (nir + red))\n",
    "    #ndvi = normalise_ndvi(ndvi)\n",
    "\n",
    "    # Ensure 3D shape\n",
    "    ndvi = ndvi[:, :, np.newaxis] if ndvi.ndim == 2 else ndvi\n",
    "    vv = vv[:, :, np.newaxis] if vv.ndim == 2 else vv\n",
    "    vh = vh[:, :, np.newaxis] if vh.ndim == 2 else vh\n",
    "    alt = alt[:, :, np.newaxis] if alt.ndim == 2 else alt\n",
    "    lon_norm = lon_norm[:, :, np.newaxis] if lon_norm.ndim == 2 else lon_norm\n",
    "    lat_norm = lat_norm[:, :, np.newaxis] if lat_norm.ndim == 2 else lat_norm\n",
    "\n",
    "    # Concatenate\n",
    "    image = np.concatenate([\n",
    "        optical_norm,  # 9\n",
    "        ndvi,          # 1\n",
    "        vv,            # 1\n",
    "        vh,            # 1\n",
    "        alt,           # 1\n",
    "        lon_norm,      # 1\n",
    "        lat_norm       # 1\n",
    "    ], axis=2)  # Total: 15 bands\n",
    "\n",
    "    if image.shape[2] != 15:\n",
    "        if image.shape[2] < 15:\n",
    "            padding = np.zeros((image.shape[0], image.shape[1], 15 - image.shape[2]))\n",
    "            image = np.concatenate([image, padding], axis=2)\n",
    "        else:\n",
    "            image = image[:, :, :15]\n",
    "\n",
    "    return np.nan_to_num(image, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "def preprocess_southeast_asia(x_img, image_path=None, transform=None, crs=None):\n",
    "    \"\"\"Preprocess image for Southeast Asia model (same as Latin America).\"\"\"\n",
    "    return preprocess_latin_america(x_img, image_path, transform, crs)\n",
    "\n",
    "# Add functions to REGION_CONFIGS\n",
    "REGION_CONFIGS['Africa']['preprocess_function'] = preprocess_africa\n",
    "REGION_CONFIGS['Southeast Asia']['preprocess_function'] = preprocess_southeast_asia\n",
    "REGION_CONFIGS['Latin America']['preprocess_function'] = preprocess_latin_america\n",
    "\n",
    "print(\"‚úÖ Preprocessing functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfuNqUqDvZZq"
   },
   "source": [
    "# ## 6. HELPER FUNCTIONS FOR SENTINEL-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "RfCADXjGv5bt",
    "outputId": "844e5a15-ddfd-47f5-e5f3-f58c81998d00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper functions\n",
    "def preproc_s1(s1_collection):\n",
    "    \"\"\"\n",
    "    Preprocesses an S1 image collection with slope correction and edge masking\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s1_collection : ee.ImageCollection\n",
    "        An S1 image collection on float/amplitude format (not dB)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    s1_collection : ee.ImageCollection\n",
    "        The slope-corrected and edge-masked S1 image collection, coverted to dB scaling\n",
    "\n",
    "    \"\"\"\n",
    "    # Do the slope correction\n",
    "    s1_collection = slope_correction(s1_collection)\n",
    "\n",
    "    # Mask the edge noise\n",
    "    s1_collection = s1_collection.map(maskAngGT30)\n",
    "    s1_collection = s1_collection.map(maskAngLT452)\n",
    "\n",
    "    # Convert to dB\n",
    "    s1_collection = s1_collection.map(lin_to_db)\n",
    "\n",
    "    return ee.ImageCollection(s1_collection)\n",
    "\n",
    "'''\n",
    "Code below is adopted from adugnag/gee_s1_ard\n",
    "'''\n",
    "\n",
    "def slope_correction(collection,\n",
    "                     TERRAIN_FLATTENING_MODEL = 'VOLUME',\n",
    "                     DEM = ee.Image('USGS/SRTMGL1_003'),\n",
    "                     TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER = 0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    collection : ee image collection\n",
    "        DESCRIPTION.\n",
    "    TERRAIN_FLATTENING_MODEL : string\n",
    "        The radiometric terrain normalization model, either volume or direct\n",
    "    DEM : ee asset\n",
    "        The DEM to be used\n",
    "    TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER : integer\n",
    "        The additional buffer to account for the passive layover and shadow\n",
    "    Returns\n",
    "    -------\n",
    "    ee image collection\n",
    "        An image collection where radiometric terrain normalization is\n",
    "        implemented on each image\n",
    "    \"\"\"\n",
    "\n",
    "    ninetyRad = ee.Image.constant(90).multiply(math.pi/180)\n",
    "\n",
    "    def _volumetric_model_SCF(theta_iRad, alpha_rRad):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        theta_iRad : ee.Image\n",
    "            The scene incidence angle\n",
    "        alpha_rRad : ee.Image\n",
    "            Slope steepness in range\n",
    "        Returns\n",
    "        -------\n",
    "        ee.Image\n",
    "            Applies the volume model in the radiometric terrain normalization\n",
    "        \"\"\"\n",
    "\n",
    "        # Volume model\n",
    "        nominator = (ninetyRad.subtract(theta_iRad).add(alpha_rRad)).tan()\n",
    "        denominator = (ninetyRad.subtract(theta_iRad)).tan()\n",
    "        return nominator.divide(denominator)\n",
    "\n",
    "    def _direct_model_SCF(theta_iRad, alpha_rRad, alpha_azRad):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        theta_iRad : ee.Image\n",
    "            The scene incidence angle\n",
    "        alpha_rRad : ee.Image\n",
    "            Slope steepness in range\n",
    "        Returns\n",
    "        -------\n",
    "        ee.Image\n",
    "            Applies the direct model in the radiometric terrain normalization\n",
    "        \"\"\"\n",
    "        # Surface model\n",
    "        nominator = (ninetyRad.subtract(theta_iRad)).cos()\n",
    "        denominator = alpha_azRad.cos().multiply((ninetyRad.subtract(theta_iRad).add(alpha_rRad)).cos())\n",
    "        return nominator.divide(denominator)\n",
    "\n",
    "    def _erode(image, distance):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : ee.Image\n",
    "            Image to apply the erode function to\n",
    "        distance : integer\n",
    "            The distance to apply the buffer\n",
    "        Returns\n",
    "        -------\n",
    "        ee.Image\n",
    "            An image that is masked to conpensate for passive layover\n",
    "            and shadow depending on the given distance\n",
    "        \"\"\"\n",
    "        # buffer function (thanks Noel)\n",
    "\n",
    "        d = (image.Not().unmask(1).fastDistanceTransform(30).sqrt()\n",
    "             .multiply(ee.Image.pixelArea().sqrt()))\n",
    "\n",
    "        return image.updateMask(d.gt(distance))\n",
    "\n",
    "    def _masking(alpha_rRad, theta_iRad, buffer):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha_rRad : ee.Image\n",
    "            Slope steepness in range\n",
    "        theta_iRad : ee.Image\n",
    "            The scene incidence angle\n",
    "        buffer : TYPE\n",
    "            DESCRIPTION.\n",
    "        Returns\n",
    "        -------\n",
    "        ee.Image\n",
    "            An image that is masked to conpensate for passive layover\n",
    "            and shadow depending on the given distance\n",
    "        \"\"\"\n",
    "        # calculate masks\n",
    "        # layover, where slope > radar viewing angle\n",
    "        layover = alpha_rRad.lt(theta_iRad).rename('layover')\n",
    "        # shadow\n",
    "        shadow = alpha_rRad.gt(ee.Image.constant(-1)\n",
    "                        .multiply(ninetyRad.subtract(theta_iRad))).rename('shadow')\n",
    "        # combine layover and shadow\n",
    "        mask = layover.And(shadow)\n",
    "        # add buffer to final mask\n",
    "        if (buffer > 0):\n",
    "            mask = _erode(mask, buffer)\n",
    "        return mask.rename('no_data_mask')\n",
    "\n",
    "    def _correct(image):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : ee.Image\n",
    "            Image to apply the radiometric terrain normalization to\n",
    "        Returns\n",
    "        -------\n",
    "        ee.Image\n",
    "            Radiometrically terrain corrected image\n",
    "        \"\"\"\n",
    "\n",
    "        bandNames = image.bandNames()\n",
    "\n",
    "        geom = image.geometry()\n",
    "        proj = image.select(1).projection()\n",
    "\n",
    "        elevation = DEM.resample('bilinear').reproject(proj,None, 10).clip(geom)\n",
    "\n",
    "        # calculate the look direction\n",
    "        heading = ee.Terrain.aspect(image.select('angle')).reduceRegion(ee.Reducer.mean(), image.geometry(), 1000)\n",
    "\n",
    "\n",
    "        #in case of null values for heading replace with 0\n",
    "        heading = ee.Dictionary(heading).combine({'aspect': 0}, False).get('aspect')\n",
    "\n",
    "        heading = ee.Algorithms.If(\n",
    "            ee.Number(heading).gt(180),\n",
    "            ee.Number(heading).subtract(360),\n",
    "            ee.Number(heading)\n",
    "        )\n",
    "\n",
    "        # the numbering follows the article chapters\n",
    "        # 2.1.1 Radar geometry\n",
    "        theta_iRad = image.select('angle').multiply(math.pi/180)\n",
    "        phi_iRad = ee.Image.constant(heading).multiply(math.pi/180)\n",
    "\n",
    "        # 2.1.2 Terrain geometry\n",
    "        alpha_sRad = ee.Terrain.slope(elevation).select('slope').multiply(math.pi / 180)\n",
    "\n",
    "        aspect = ee.Terrain.aspect(elevation).select('aspect').clip(geom)\n",
    "\n",
    "        aspect_minus = aspect.updateMask(aspect.gt(180)).subtract(360)\n",
    "\n",
    "        phi_sRad = aspect.updateMask(aspect.lte(180))\\\n",
    "            .unmask()\\\n",
    "            .add(aspect_minus.unmask())\\\n",
    "            .multiply(-1)\\\n",
    "            .multiply(math.pi / 180)\n",
    "\n",
    "        #elevation = DEM.reproject(proj,None, 10).clip(geom)\n",
    "\n",
    "        # 2.1.3 Model geometry\n",
    "        # reduce to 3 angle\n",
    "        phi_rRad = phi_iRad.subtract(phi_sRad)\n",
    "\n",
    "        # slope steepness in range (eq. 2)\n",
    "        alpha_rRad = (alpha_sRad.tan().multiply(phi_rRad.cos())).atan()\n",
    "\n",
    "        # slope steepness in azimuth (eq 3)\n",
    "        alpha_azRad = (alpha_sRad.tan().multiply(phi_rRad.sin())).atan()\n",
    "\n",
    "        # 2.2\n",
    "        # Gamma_nought\n",
    "        gamma0 = image.divide(theta_iRad.cos())\n",
    "\n",
    "        if (TERRAIN_FLATTENING_MODEL == 'VOLUME'):\n",
    "            # Volumetric Model\n",
    "            scf = _volumetric_model_SCF(theta_iRad, alpha_rRad)\n",
    "\n",
    "        if (TERRAIN_FLATTENING_MODEL == 'DIRECT'):\n",
    "            scf = _direct_model_SCF(theta_iRad, alpha_rRad, alpha_azRad)\n",
    "\n",
    "        # apply model for Gamm0\n",
    "        gamma0_flat = gamma0.multiply(scf)\n",
    "\n",
    "        # get Layover/Shadow mask\n",
    "        mask = _masking(alpha_rRad, theta_iRad, TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER)\n",
    "        output = gamma0_flat.mask(mask).rename(bandNames).copyProperties(image)\n",
    "        output = ee.Image(output).addBands(image.select('angle'), None, True)\n",
    "\n",
    "        return output.set('system:time_start', image.get('system:time_start'))\n",
    "    return collection.map(_correct)\n",
    "\n",
    "\n",
    "def maskAngLT452(image):\n",
    "    \"\"\"\n",
    "    mask out angles >= 45.23993\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ee.Image\n",
    "        image to apply the border noise masking\n",
    "    Returns\n",
    "    -------\n",
    "    ee.Image\n",
    "        Masked image\n",
    "    \"\"\"\n",
    "    ang = image.select(['angle'])\n",
    "    return image.updateMask(ang.lt(45.23993)).set('system:time_start', image.get('system:time_start'))\n",
    "\n",
    "\n",
    "def maskAngGT30(image):\n",
    "    \"\"\"\n",
    "    mask out angles <= 30.63993\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ee.Image\n",
    "        image to apply the border noise masking\n",
    "    Returns\n",
    "    -------\n",
    "    ee.Image\n",
    "        Masked image\n",
    "    \"\"\"\n",
    "\n",
    "    ang = image.select(['angle'])\n",
    "    return image.updateMask(ang.gt(30.63993)).set('system:time_start', image.get('system:time_start'))\n",
    "\n",
    "\n",
    "def lin_to_db(image):\n",
    "    \"\"\"\n",
    "    Convert backscatter from linear to dB.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ee.Image\n",
    "        Image to convert\n",
    "    Returns\n",
    "    -------\n",
    "    ee.Image\n",
    "        output image\n",
    "    \"\"\"\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "    db = ee.Image.constant(10).multiply(image.select(bandNames).log10()).rename(bandNames)\n",
    "    return image.addBands(db, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdD0HhNHv7xG"
   },
   "source": [
    "# ## 7. EARTH ENGINE DATA DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VpKGuobBwJjd",
    "outputId": "f8a03dc7-4fea-46f9-b956-30a74e6dee26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Earth Engine functions defined!\n"
     ]
    }
   ],
   "source": [
    "#Define Quality assessment bands and threshold\n",
    "QA_BAND = 'cs_cdf'\n",
    "CLEAR_THRESHOLD = 0.40\n",
    "def clearMask(img):\n",
    "\n",
    "    img = img.toFloat().resample('bilinear').reproject(img.select('B2').projection())\n",
    "    return img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD))\n",
    "\n",
    "def get_sentinel2_composite(bbox, start_date, end_date):\n",
    "    \"\"\"Get cloud-free Sentinel-2 composite.\"\"\"\n",
    "    s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "    csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED').filterDate(start_date, end_date)\n",
    "\n",
    "\n",
    "    s2_masked = s2.filterBounds(bbox).filterDate(start_date, end_date).linkCollection(csPlus, [QA_BAND])\\\n",
    "    .map(clearMask).median().select(S2_BANDS).clip(bbox)\n",
    "\n",
    "    return s2_masked\n",
    "\n",
    "\n",
    "\n",
    "def get_sentinel1_composite(bbox, start_date, end_date):\n",
    "    \"\"\"Get Sentinel-1 composite.\"\"\"\n",
    "    s1 = ee.ImageCollection('COPERNICUS/S1_GRD_FLOAT')\n",
    "    s1_filtered = s1.filterBounds(bbox)\\\n",
    "                    .filterDate(start_date, end_date)\\\n",
    "                    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "\n",
    "    # Preprocess the image collection\n",
    "    s1_preproc = preproc_s1(s1_filtered)\n",
    "\n",
    "    # Select the relevant bands\n",
    "    s1_preproc = s1_preproc.select('VV', 'VH')\n",
    "\n",
    "    # Create a median composite\n",
    "    s1_composite = s1_preproc.median()\n",
    "\n",
    "    return s1_composite.clip(bbox)\n",
    "\n",
    "\n",
    "def get_elevation_data(bbox):\n",
    "    \"\"\"Get elevation data.\"\"\"\n",
    "    #elevation = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
    "    elevation = ee.ImageCollection('COPERNICUS/DEM/GLO30').select('DEM').mosaic()\n",
    "    return elevation.clip(bbox)\n",
    "\n",
    "def get_forest_loss_data(bbox):\n",
    "    \"\"\"Get Hansen forest loss data.\"\"\"\n",
    "    loss_dataset = ee.Image('UMD/hansen/global_forest_change_2023_v1_11')\n",
    "    return loss_dataset.select(['loss']).clip(bbox)\n",
    "\n",
    "def download_region_data(bbox, region_name, start_date=START_DATE, end_date=END_DATE,\n",
    "                         scale=10, output_dir='downloads'):\n",
    "    \"\"\"\n",
    "    Download all required data for a region.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to downloaded GeoTIFF\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"üì• Downloading data for {region_name}...\")\n",
    "\n",
    "    # Get all data layers\n",
    "    s2 = get_sentinel2_composite(bbox, start_date, end_date)\n",
    "    s1 = get_sentinel1_composite(bbox, start_date, end_date)\n",
    "    elevation = get_elevation_data(bbox)\n",
    "    loss = get_forest_loss_data(bbox)\n",
    "\n",
    "    # Add longitude and latitude bands\n",
    "    lonlat = ee.Image.pixelLonLat()\n",
    "\n",
    "    # Stack all bands\n",
    "    image = s2.addBands(s1)\\\n",
    "              .addBands(elevation)\\\n",
    "              .addBands(lonlat.select('longitude'))\\\n",
    "              .addBands(lonlat.select('latitude'))\\\n",
    "              .addBands(loss)\\\n",
    "              .int16()\n",
    "\n",
    "    # Export\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_path = os.path.join(output_dir, f'{region_name.replace(\" \", \"_\")}_{timestamp}.tif')\n",
    "\n",
    "    print(f\"Exporting to {output_path}...\")\n",
    "    geemap.ee_export_image(\n",
    "        image,\n",
    "        filename=output_path,\n",
    "        scale=scale,\n",
    "        region=bbox,\n",
    "        file_per_band=False\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Data downloaded to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "print(\"‚úÖ Earth Engine functions defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07T7odfYwWLl"
   },
   "source": [
    "# ## 8. PREDICTION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "H7IIf31twnsO",
    "outputId": "8eb74c4d-a729-4a53-b79e-4ec696978041"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prediction functions defined!\n"
     ]
    }
   ],
   "source": [
    "def pad_image_for_tiling(image, patch_size, padding_mode='reflect'):\n",
    "    \"\"\"\n",
    "    Pad image for tiled prediction.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (H, W, C)\n",
    "        patch_size: Size of patches\n",
    "        padding_mode: Padding mode\n",
    "\n",
    "    Returns:\n",
    "        tuple: (padded_image, (pad_top, pad_left))\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "\n",
    "    pad_h = (patch_size - h % patch_size) % patch_size\n",
    "    pad_w = (patch_size - w % patch_size) % patch_size\n",
    "\n",
    "    if pad_h > 0 or pad_w > 0:\n",
    "        pad_top = pad_h // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "        pad_left = pad_w // 2\n",
    "        pad_right = pad_w - pad_left\n",
    "\n",
    "        padded_image = np.pad(\n",
    "            image,\n",
    "            ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)),\n",
    "            mode=padding_mode\n",
    "        )\n",
    "        return padded_image, (pad_top, pad_left)\n",
    "\n",
    "    return image, (0, 0)\n",
    "\n",
    "def predict_tiled_onnx(model_session, image, patch_size=64):\n",
    "    \"\"\"\n",
    "    Predict on large image using tiling with ONNX model.\n",
    "\n",
    "    Args:\n",
    "        model_session: ONNX Runtime session\n",
    "        image: Input image (H, W, C)\n",
    "        patch_size: Size of patches\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Predictions (H, W, num_classes)\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "\n",
    "    # Get model info\n",
    "    input_name = model_session.get_inputs()[0].name\n",
    "    output_name = model_session.get_outputs()[0].name\n",
    "    input_shape = model_session.get_inputs()[0].shape\n",
    "\n",
    "    # Determine number of classes\n",
    "    if len(model_session.get_outputs()[0].shape) == 4:\n",
    "        output_shape = model_session.get_outputs()[0].shape\n",
    "        num_classes = output_shape[1] if output_shape[1] <= 4 else output_shape[-1]\n",
    "    else:\n",
    "        num_classes = model_session.get_outputs()[0].shape[-1]\n",
    "\n",
    "    # Initialize output\n",
    "    predictions = np.zeros((h, w, num_classes), dtype=np.float32)\n",
    "\n",
    "    # Determine if model expects channels-first\n",
    "    transpose_needed = (len(input_shape) == 4 and input_shape[1] <= 4)\n",
    "\n",
    "    # Process in patches\n",
    "    step = patch_size // 8  # 50% overlap\n",
    "\n",
    "    for i in range(0, h, step):\n",
    "        for j in range(0, w, step):\n",
    "            # Calculate actual patch boundaries\n",
    "            i_start = i\n",
    "            i_end = min(i + patch_size, h)\n",
    "            j_start = j\n",
    "            j_end = min(j + patch_size, w)\n",
    "\n",
    "            # Get actual patch size (might be smaller at edges)\n",
    "            actual_patch_height = i_end - i_start\n",
    "            actual_patch_width = j_end - j_start\n",
    "\n",
    "            patch = image[i_start:i_end, j_start:j_end, :]\n",
    "\n",
    "            # Pad if needed for model input\n",
    "            if patch.shape[0] < patch_size or patch.shape[1] < patch_size:\n",
    "                pad_h = patch_size - patch.shape[0] if patch.shape[0] < patch_size else 0\n",
    "                pad_w = patch_size - patch.shape[1] if patch.shape[1] < patch_size else 0\n",
    "                patch = np.pad(patch, ((0, pad_h), (0, pad_w), (0, 0)), mode='reflect')\n",
    "\n",
    "\n",
    "\n",
    "            # Add batch dimension\n",
    "            patch_batch = np.expand_dims(patch, axis=0).astype(np.float32)\n",
    "\n",
    "            # Transpose if needed\n",
    "            if transpose_needed:\n",
    "                patch_batch = np.transpose(patch_batch, (0, 3, 1, 2))\n",
    "\n",
    "            # Run inference\n",
    "            pred_patch = model_session.run(\n",
    "                [output_name],\n",
    "                {input_name: patch_batch}\n",
    "            )[0]\n",
    "\n",
    "            # Remove batch dimension\n",
    "            if pred_patch.shape[0] == 1:\n",
    "                pred_patch = pred_patch[0]\n",
    "\n",
    "            # Transpose back if needed\n",
    "            if transpose_needed and len(pred_patch.shape) == 3:\n",
    "                pred_patch = np.transpose(pred_patch, (1, 2, 0))\n",
    "            elif transpose_needed and len(pred_patch.shape) == 4:\n",
    "                pred_patch = pred_patch[0]\n",
    "                pred_patch = np.transpose(pred_patch, (1, 2, 0))\n",
    "\n",
    "            # Accumulate\n",
    "            #pred_h, pred_w = pred_patch.shape[:2]\n",
    "            #predictions[i:i+pred_h, j:j+pred_w, :] = pred_patch\n",
    "\n",
    "            # After prediction, crop back to actual size\n",
    "            if actual_patch_height < patch_size or actual_patch_width < patch_size:\n",
    "                # Crop the prediction back to actual patch size\n",
    "                pred_patch = pred_patch[:actual_patch_height, :actual_patch_width, :]\n",
    "\n",
    "            # Then assign to predictions array\n",
    "            predictions[i_start:i_start+actual_patch_height, j_start:j_start+actual_patch_width, :] = pred_patch\n",
    "\n",
    "\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def predict_land_use(model_session, config, image_path, output_dir='predictions'):\n",
    "    \"\"\"\n",
    "    Run follow-up land use prediction on downloaded image.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (prediction_path, confidence_path, class_names)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"üß† Starting prediction for {config.get('region_name', 'Unknown')}\")\n",
    "\n",
    "    # Read image\n",
    "    with rasterio.open(image_path) as src:\n",
    "        x_img = src.read()\n",
    "        print(f\"Original shape from rasterio (bands, height, width): {x_img.shape}\")\n",
    "        # Get the height, width, and count of bands from the metadata\n",
    "        height = src.height\n",
    "        width = src.width\n",
    "        bands = src.count # This should be 15 for your image\n",
    "        x_img = reshape_as_image(x_img)\n",
    "        print(\"Last band min/max:\", x_img[:, :, -1].min(), x_img[:, :, -1].max())\n",
    "        print(f\"Reshaped image shape (height, width, bands): {x_img.shape}\")\n",
    "        #x_img = np.moveaxis(x_img, 0, -1)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        profile = src.profile.copy()\n",
    "\n",
    "    print(f\"Input image shape: {x_img.shape}\")\n",
    "\n",
    "    # Extract loss band (last band)\n",
    "    if x_img.shape[2] >= 15:\n",
    "        loss = x_img[:, :, -1]#.astype(np.uint8)\n",
    "        print(\"Loss unique values:\", np.unique(loss))\n",
    "        x_img_input = x_img[:, :, :14]  # Use first 14 bands\n",
    "    else:\n",
    "        loss = x_img[:, :, -1]#np.zeros_like(x_img[:, :, 0])\n",
    "        x_img_input = x_img\n",
    "\n",
    "    # Preprocess\n",
    "    preprocess_func = config.get('preprocess_function', preprocess_africa)\n",
    "    x_img_processed = preprocess_func(x_img_input, image_path=image_path, transform=transform, crs=crs)\n",
    "    print(f\"x_img_processed image shape: {x_img_processed.shape}\")\n",
    "\n",
    "    # Pad for tiling\n",
    "    padded_image, pad_coords = pad_image_for_tiling(x_img_processed, PATCH_SIZE)\n",
    "\n",
    "    print(f\"padded_image image shape: {padded_image.shape}\")\n",
    "\n",
    "    # Predict\n",
    "    print(\"Running inference...\")\n",
    "    predictions = predict_tiled_onnx(model_session, padded_image, PATCH_SIZE)\n",
    "\n",
    "    # Remove padding\n",
    "    if pad_coords[0] > 0 or pad_coords[1] > 0:\n",
    "        predictions = predictions[pad_coords[0]:pad_coords[0]+x_img.shape[0],\n",
    "                                 pad_coords[1]:pad_coords[1]+x_img.shape[1], :]\n",
    "\n",
    "    # Final prediction\n",
    "    final_prediction = np.argmax(predictions, axis=2).astype(np.uint8)\n",
    "    print(\"Loss unique values2:\", np.unique(loss))\n",
    "    final_prediction = np.where(loss == 0, 0, final_prediction)  # Mask non-loss areas\n",
    "\n",
    "    print(f\"final_prediction image shape: {final_prediction.shape}\")\n",
    "\n",
    "    # Confidence\n",
    "    #confidence = np.max(predictions, axis=2)\n",
    "    #confidence = np.nan_to_num(confidence, nan=0, posinf=100, neginf=0)\n",
    "    #confidence = confidence * 100\n",
    "    #confidence = np.clip(confidence, 0, 100)  # Clip to valid range\n",
    "    #confidence = confidence.astype(np.uint8)\n",
    "\n",
    "    # Confidence\n",
    "    confidence = np.max(predictions, axis=2)\n",
    "\n",
    "    # Check if there are any -inf or invalid values\n",
    "    print(f\"Confidence stats before cleaning: min={confidence.min():.6f}, max={confidence.max():.6f}\")\n",
    "    print(f\"Has -inf: {np.any(np.isneginf(confidence))}\")\n",
    "    print(f\"Has inf: {np.any(np.isinf(confidence))}\")\n",
    "    print(f\"Has nan: {np.any(np.isnan(confidence))}\")\n",
    "\n",
    "    # Replace all infinities and NaNs with 0\n",
    "    confidence = np.where(np.isinf(confidence), 0, confidence)\n",
    "    confidence = np.where(np.isneginf(confidence), 0, confidence)\n",
    "    confidence = np.where(np.isnan(confidence), 0, confidence)\n",
    "\n",
    "    # Now scale to 0-100 range\n",
    "    confidence = confidence * 100\n",
    "\n",
    "    # Clip to ensure values are within 0-100 range\n",
    "    confidence = np.clip(confidence, 0, 100)\n",
    "\n",
    "    # Convert to uint8\n",
    "    confidence = confidence.astype(np.uint8)\n",
    "    confidence = np.where(loss == 0, 0, confidence)  # Mask non-loss areas\n",
    "\n",
    "    print(f\"Confidence stats after cleaning: min={confidence.min()}, max={confidence.max()}\")\n",
    "\n",
    "    print(f\"confidence image shape: {confidence.shape}\")\n",
    "\n",
    "    # Save results\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    # Save prediction\n",
    "    pred_path = os.path.join(output_dir, f'{base_name}_landuse.tif')\n",
    "    #profile.update(dtype='uint8', count=1, compress='lzw')\n",
    "    profile.update(dtype='uint8', count=1, compress='lzw', nodata=0)\n",
    "\n",
    "    with rasterio.open(pred_path, 'w', **profile) as dst:\n",
    "        # Reshape to 3D if needed\n",
    "        #if final_prediction.ndim == 2:\n",
    "          #final_prediction = final_prediction.reshape(1, final_prediction.shape[0], final_prediction.shape[1])\n",
    "        #dst.write(final_prediction)\n",
    "\n",
    "        if final_prediction.ndim == 2:\n",
    "            # Keep it as 2D, rasterio will handle it properly\n",
    "            pass\n",
    "\n",
    "        dst.write(final_prediction, 1)  # Write as single band\n",
    "\n",
    "    #with rasterio.open(pred_path, 'w', **profile) as dst:\n",
    "        #dst.write(final_prediction, 1)\n",
    "        dst.update_tags(\n",
    "            classes=','.join(config.get('classes', [])),\n",
    "            region=config.get('region_name', 'Unknown'),\n",
    "            model=config.get('model_name', 'Unknown')\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    # Save confidence\n",
    "    conf_path = os.path.join(output_dir, f'{base_name}_confidence.tif')\n",
    "    with rasterio.open(conf_path, 'w', **profile) as dst:\n",
    "        dst.write(confidence, 1)\n",
    "\n",
    "    print(f\"‚úÖ Predictions saved to {pred_path}\")\n",
    "\n",
    "    return pred_path, conf_path, config.get('classes', [])\n",
    "\n",
    "print(\"‚úÖ Prediction functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCLPrzx_wzJi"
   },
   "source": [
    "# ## 9. VISUALIZATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "7paKOclJxBDB",
    "outputId": "d1d10f3f-e2b8-4a3b-83df-379b1d509e42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Visualization functions defined!\n"
     ]
    }
   ],
   "source": [
    "def create_legend(classes, color_map):\n",
    "    \"\"\"\n",
    "    Create matplotlib legend for land use classes.\n",
    "\n",
    "    Args:\n",
    "        classes: List of class names\n",
    "        color_map: Matplotlib colormap\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Legend figure\n",
    "    \"\"\"\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    n_cols = int(np.ceil(n_classes / 3))\n",
    "    #fig, ax = plt.subplots(figsize=(8, 10))\n",
    "    #fig, ax = plt.subplots(figsize=(15, 4))\n",
    "    fig, ax = plt.subplots(figsize=(15, 3))\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    colors = [color_map(i / max(1, n_classes - 1)) for i in range(n_classes)]\n",
    "\n",
    "    for i, (class_name, color) in enumerate(zip(classes, colors)):\n",
    "        #ax.add_patch(plt.Rectangle((0, n_classes - i - 1), 0.3, 0.8,\n",
    "        #                          facecolor=color, edgecolor='black'))\n",
    "        #ax.text(0.4, n_classes - i - 0.6, f'{i}: {class_name}',\n",
    "        #        fontsize=9, va='center')\n",
    "\n",
    "        row = i // n_cols\n",
    "        col = i % n_cols\n",
    "\n",
    "        x = col * 3.5\n",
    "        y = 2 - row  # 3 rows: 2,1,0\n",
    "\n",
    "        ax.add_patch(plt.Rectangle((x, y), 0.3, 0.5,\n",
    "                                  facecolor=color, edgecolor='black'))\n",
    "        ax.text(x + 0.4, y + 0.25, f'{i}: {class_name}',\n",
    "                fontsize=9, va='center')\n",
    "\n",
    "    #ax.set_xlim(0, 5)\n",
    "    #ax.set_ylim(0, n_classes)\n",
    "    ax.set_xlim(0, n_cols * 3.5)\n",
    "    ax.set_ylim(-2.4, 3)\n",
    "    ax.set_title('Follow-up Land Use Classes', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "    # Abbreviations (below legend)\n",
    "    ax.text(\n",
    "        0,\n",
    "        -1.2,\n",
    "        'Abbreviations:',\n",
    "        fontsize=10,\n",
    "        fontweight='bold',\n",
    "        ha='left',\n",
    "        va='top'\n",
    "    )\n",
    "\n",
    "    ax.text(\n",
    "        0,\n",
    "        -1.7,\n",
    "        'OLSCP ‚Äì Other large-scale cropland',\n",
    "        fontsize=9,\n",
    "        ha='left',\n",
    "        va='top'\n",
    "    )\n",
    "\n",
    "    ax.text(\n",
    "        0,\n",
    "        -2.1,\n",
    "        'OSSCP ‚Äì Other small-scale cropland',\n",
    "        fontsize=9,\n",
    "        ha='left',\n",
    "        va='top'\n",
    "    )\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def visualize_results(image_path, prediction_path, confidence_path, classes, region_name):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of results.\n",
    "    \"\"\"\n",
    "    #fig = plt.figure(figsize=(18, 12))\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "\n",
    "    # Read input image (RGB)\n",
    "    with rasterio.open(image_path) as src:\n",
    "        rgb = src.read([4, 3, 2])  # B4=Red, B3=Green, B2=Blue\n",
    "        print(f\"rgb shape after clip: {rgb.shape}\")\n",
    "        rgb = np.moveaxis(rgb, 0, -1)\n",
    "        print(f\"rgb shape after clip: {rgb.shape}\")\n",
    "        rgb = np.clip(rgb / 3000, 0, 1)\n",
    "        print(f\"rgb shape after clip: {rgb.shape}\")\n",
    "\n",
    "    # Read prediction\n",
    "    #with rasterio.open(prediction_path) as src:\n",
    "    #    prediction = src.read(1)\n",
    "\n",
    "    # Read prediction\n",
    "    with rasterio.open(prediction_path) as src:\n",
    "        prediction = src.read(1)  # This returns a 2D array\n",
    "        print(f\"Prediction shape after read(1): {prediction.shape}\")\n",
    "        print(f\"Prediction dtype: {prediction.dtype}\")\n",
    "        print(f\"Prediction min/max: {prediction.min()}, {prediction.max()}\")\n",
    "\n",
    "\n",
    "    # Read confidence\n",
    "    with rasterio.open(confidence_path) as src:\n",
    "        confidence = src.read(1)\n",
    "\n",
    "    # Get loss mask\n",
    "    with rasterio.open(image_path) as src:\n",
    "        if src.count > 15:\n",
    "            loss = src.read(src.count)\n",
    "            loss = loss.squeeze()  # Remove the first dimension if it's 1\n",
    "            print(f\"loss shape after src read and squeeze: {loss.shape}\")\n",
    "            print(f\"loss min/max: {loss.min()}, {loss.max()}\")\n",
    "        else:\n",
    "            loss = np.zeros_like(prediction)\n",
    "            print(f\"loss shape zeros like prediction: {loss.shape}\")\n",
    "\n",
    "    print(f\"loss shape: {loss.shape}\")\n",
    "\n",
    "    # Mask for deforested areas\n",
    "    deforested_mask = (loss > 0) #& (prediction > 0)\n",
    "    #deforested_mask = prediction > 0 #(loss > 0) #& (prediction > 0)\n",
    "    print(f\"deforested_mask shape: {deforested_mask.shape}\")\n",
    "\n",
    "    # 1. RGB with deforestation highlight\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    rgb_highlighted = rgb.copy()\n",
    "    assert rgb_highlighted.ndim == 3\n",
    "    assert deforested_mask.shape == rgb_highlighted.shape[:2]\n",
    "    mask3 = deforested_mask[:, :, None]\n",
    "    rgb_highlighted = np.where(\n",
    "        mask3,\n",
    "        np.array([1.0, 0.0, 0.0]),\n",
    "        rgb_highlighted\n",
    "    )\n",
    "    ax1.imshow(rgb_highlighted)\n",
    "    #ax1.set_title('RGB with Deforestation Highlight', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Satellite Image - False color', fontsize=11, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # 2. Follow-up Land use prediction\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    prediction_masked = np.where(deforested_mask, prediction, 0)\n",
    "\n",
    "    print(f\"rgb_highlighted shape: {rgb_highlighted.shape}\")\n",
    "    print(f\"deforested_mask shape: {deforested_mask.shape}\")\n",
    "\n",
    "    color_map = REGION_CONFIGS[region_name]['color_map']\n",
    "    #im2 = ax2.imshow(prediction_masked, cmap=color_map, vmin=0, vmax=max(1, len(classes)-1))\n",
    "    im2 = ax2.imshow(prediction, cmap=color_map, vmin=0, vmax=max(1, len(classes)-1))\n",
    "    ax2.set_title('Follow-up Land Use Prediction', fontsize=11, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    plt.colorbar(im2, ax=ax2, fraction=0.026, pad=0.04)\n",
    "\n",
    "    # 3. Prediction confidence\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    confidence_masked = np.where(deforested_mask, confidence, 0)\n",
    "    #im3 = ax3.imshow(confidence_masked, cmap='RdYlGn', vmin=0, vmax=100)\n",
    "    im3 = ax3.imshow(confidence, cmap='gnuplot2', vmin=0, vmax=100)\n",
    "    ax3.set_title('Prediction Confidence (%)', fontsize=11, fontweight='bold')\n",
    "    ax3.axis('off')\n",
    "    plt.colorbar(im3, ax=ax3, fraction=0.026, pad=0.04)\n",
    "\n",
    "    # 4. Class distribution\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    unique_classes, counts = np.unique(prediction[prediction > 0], return_counts=True)\n",
    "    if len(unique_classes) > 0:\n",
    "        colors = [color_map(cls / max(1, len(classes)-1)) for cls in unique_classes]\n",
    "        ax4.bar(range(len(unique_classes)), counts, color=colors, edgecolor='black')\n",
    "        ax4.set_xticks(range(len(unique_classes)))\n",
    "        ax4.set_xticklabels([str(int(cls)) for cls in unique_classes])\n",
    "        ax4.set_xlabel('Class ID')\n",
    "        ax4.set_ylabel('Pixel Count')\n",
    "        ax4.set_title('Class Distribution', fontsize=11, fontweight='bold')\n",
    "        ax4.grid(alpha=0.3)\n",
    "\n",
    "    # 5. Confidence histogram\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    ax5.hist(confidence[confidence > 0].flatten(), bins=20, edgecolor='black', alpha=0.7)\n",
    "    ax5.set_xlabel('Confidence (%)')\n",
    "    ax5.set_ylabel('Frequency')\n",
    "    ax5.set_title('Confidence Distribution', fontsize=11, fontweight='bold')\n",
    "    ax5.grid(alpha=0.3)\n",
    "\n",
    "    # 6. Region info\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    ax6.axis('off')\n",
    "    info_text = f\"\"\"\n",
    "    Region: {region_name}\n",
    "    Total Pixels: {prediction.size:,}\n",
    "    Deforested Pixels: {np.count_nonzero(prediction):,}\n",
    "    Mean Confidence: {np.mean(confidence[confidence > 0]):.1f}%\n",
    "    \"\"\"\n",
    "    ax6.text(0.1, 0.5, info_text, fontsize=10, va='center', linespacing=1.5)\n",
    "    ax6.set_title('Statistics', fontsize=11, fontweight='bold')\n",
    "\n",
    "    plt.suptitle(f'Monitoring Land Use Following Deforestation - {region_name}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ztxn576wxC4s"
   },
   "source": [
    "# ## 10. INTERACTIVE INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Kx56HPkpxXpW",
    "outputId": "1d5d0ee6-74dd-4a02-c538-3e86ba496f32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Interactive interface defined!\n"
     ]
    }
   ],
   "source": [
    "class DeforestationPredictor:\n",
    "    \"\"\"Interactive deforestation prediction tool with ONNX models\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize Earth Engine map\n",
    "        self.map = geemap.Map(\n",
    "            center=[0, 0],\n",
    "            zoom=3,\n",
    "            height=600,\n",
    "            layout=Layout(width='70%')\n",
    "        )\n",
    "\n",
    "        # ===============================\n",
    "        # ADD BASEMAP AND FOREST LOSS\n",
    "        # ===============================\n",
    "\n",
    "        # High-resolution satellite basemap\n",
    "        # Basemaps\n",
    "        self.map = geemap.Map(basemap='HYBRID')\n",
    "\n",
    "        self.map.addLayer(\n",
    "            geemap.basemaps['Esri.WorldStreetMap'],\n",
    "            {},\n",
    "            'Road map',\n",
    "            shown=False\n",
    "        )\n",
    "\n",
    "\n",
    "        # --- GLOBAL HANSEN FOREST LOSS (NO CLIP) ---\n",
    "        hansen = ee.Image('UMD/hansen/global_forest_change_2023_v1_11')\n",
    "        self.loss_img = hansen.select('loss')\n",
    "        self.lossyear_img = hansen.select('lossyear')\n",
    "\n",
    "\n",
    "        self.map.addLayer(\n",
    "            self.lossyear_img,\n",
    "            {\n",
    "                'min': 1,\n",
    "                'max': 23,\n",
    "                'palette': [\n",
    "                    '#ffffcc','#ffeda0','#fed976','#feb24c',\n",
    "                    '#fd8d3c','#fc4e2a','#e31a1c','#bd0026','#800026'\n",
    "                ]\n",
    "            },\n",
    "            'Forest loss year (global)',\n",
    "            shown=True\n",
    "        )\n",
    "\n",
    "\n",
    "        lossyear_legend = {\n",
    "            '2001': '#ffffcc',\n",
    "            '2005': '#fed976',\n",
    "            '2010': '#fd8d3c',\n",
    "            '2015': '#e31a1c',\n",
    "            '2023': '#800026'\n",
    "        }\n",
    "\n",
    "        self.map.add_legend(\n",
    "            title='Forest loss year (Hansen)',\n",
    "            legend_dict=lossyear_legend,\n",
    "            position='bottomright'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Initialize state variables\n",
    "        self.roi = None\n",
    "        self.region_name = None\n",
    "        self.region_config = {}\n",
    "        self.model_session = None\n",
    "        self.data_path = None\n",
    "        self.prediction_path = None\n",
    "        self.confidence_path = None\n",
    "        self.class_names = None\n",
    "\n",
    "        # Create output widget for logs\n",
    "        #self.output = Output(layout=Layout(width='100%', height='300px'))\n",
    "        self.output = Output(layout=Layout(width='100%'))\n",
    "\n",
    "\n",
    "        # Create control widgets\n",
    "        self._create_widgets()\n",
    "\n",
    "        # Arrange layout\n",
    "        self._create_layout()\n",
    "\n",
    "        # Initialize drawing control\n",
    "        self._setup_draw_control()\n",
    "        self.map.addLayerControl(position='topright')\n",
    "\n",
    "    def _setup_draw_control(self):\n",
    "        \"\"\"Setup draw control\"\"\"\n",
    "        self.map.clear_controls()\n",
    "        self.map.add_draw_control()\n",
    "\n",
    "        def handle_draw(target, action, geo_json):\n",
    "            if action == 'created' and geo_json:\n",
    "                self._process_drawn_geometry(geo_json)\n",
    "\n",
    "        if hasattr(self.map.draw_control, 'on_draw'):\n",
    "            self.map.draw_control.on_draw(handle_draw)\n",
    "\n",
    "\n",
    "\n",
    "    def _process_drawn_geometry(self, geo_json):\n",
    "        \"\"\"Process drawn geometry\"\"\"\n",
    "        try:\n",
    "            self.roi = ee.Geometry(geo_json['geometry'])\n",
    "\n",
    "            # Detect region\n",
    "            self.region_name = None\n",
    "            for region_name, config in REGION_CONFIGS.items():\n",
    "                bbox = config['bbox']\n",
    "                if bbox.contains(self.roi.centroid()).getInfo():\n",
    "                    self.region_name = region_name\n",
    "                    break\n",
    "\n",
    "            if self.region_name:\n",
    "                self.region_config = REGION_CONFIGS[self.region_name].copy()\n",
    "                self.region_dropdown.value = self.region_name\n",
    "\n",
    "                area_sqkm = self.roi.area().divide(1e6).getInfo()\n",
    "\n",
    "                self.region_label.value = f\"\"\"\n",
    "                <h3>üåç Region: <span style='color:green'>{self.region_name}</span></h3>\n",
    "                <p>Model: {self.region_config.get('model_name', 'Unknown')}</p>\n",
    "                <p>Classes: {self.region_config.get('output_classes', 0)}</p>\n",
    "                \"\"\"\n",
    "\n",
    "                self.roi_label.value = f\"\"\"\n",
    "                <h3>üó∫Ô∏è ROI: <span style='color:green'>{area_sqkm:.1f} km¬≤</span></h3>\n",
    "                \"\"\"\n",
    "\n",
    "                self.download_btn.disabled = False\n",
    "                self.predict_btn.disabled = True\n",
    "\n",
    "                self.status.value = f\"\"\"\n",
    "                <h4>Status: <span style='color:green'>‚úì ROI drawn in {self.region_name}</span></h4>\n",
    "                <p>Ready to download satellite data</p>\n",
    "                \"\"\"\n",
    "\n",
    "                with self.output:\n",
    "                    clear_output()\n",
    "                    print(f\"‚úì ROI drawn in {self.region_name}\")\n",
    "                    print(f\"  Area: {area_sqkm:.1f} km¬≤\")\n",
    "            else:\n",
    "                self.region_label.value = \"\"\"\n",
    "                <h3>üåç Region: <span style='color:orange'>Outside supported regions</span></h3>\n",
    "                \"\"\"\n",
    "                self.download_btn.disabled = True\n",
    "\n",
    "                with self.output:\n",
    "                    clear_output()\n",
    "                    print(\"‚ö†Ô∏è Please draw within Africa, Southeast Asia, or Latin America\")\n",
    "\n",
    "        except Exception as e:\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "    def _create_widgets(self):\n",
    "        \"\"\"Create all interactive widgets\"\"\"\n",
    "        # Region label\n",
    "        self.region_label = widgets.HTML(\n",
    "            value=\"<h3>üåç Region: <span style='color:red'>Not selected</span></h3>\",\n",
    "            layout=Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        # ROI info label\n",
    "        self.roi_label = widgets.HTML(\n",
    "            value=\"<h3>üó∫Ô∏è ROI: <span style='color:red'>Not drawn</span></h3>\",\n",
    "            layout=Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        # Download button\n",
    "        self.download_btn = widgets.Button(\n",
    "            description=\"üì• Download Satellite Data\",\n",
    "            button_style='primary',\n",
    "            disabled=True,\n",
    "            icon='download',\n",
    "            layout=Layout(width='250px', height='50px')\n",
    "        )\n",
    "        self.download_btn.on_click(self.download_data)\n",
    "\n",
    "        # Predict button\n",
    "        self.predict_btn = widgets.Button(\n",
    "            description=\"üß† Run Follow-up Land Use Prediction\",\n",
    "            button_style='success',\n",
    "            disabled=True,\n",
    "            icon='cogs',\n",
    "            layout=Layout(width='250px', height='50px')\n",
    "        )\n",
    "        self.predict_btn.on_click(self.run_prediction)\n",
    "\n",
    "        # Clear button\n",
    "        self.clear_btn = widgets.Button(\n",
    "            description=\"üóëÔ∏è Clear All\",\n",
    "            button_style='warning',\n",
    "            icon='trash',\n",
    "            layout=Layout(width='250px', height='50px')\n",
    "        )\n",
    "        self.clear_btn.on_click(self.clear_all)\n",
    "\n",
    "        # Region dropdown\n",
    "        self.region_dropdown = widgets.Dropdown(\n",
    "            options=['Africa', 'Southeast Asia', 'Latin America'],\n",
    "            value=None,\n",
    "            description='Select Region:',\n",
    "            disabled=False,\n",
    "            layout=Layout(width='300px')\n",
    "        )\n",
    "        self.region_dropdown.observe(self.on_region_change, names='value')\n",
    "\n",
    "        # ===============================\n",
    "        # FOREST LOSS YEAR SLIDER\n",
    "        # ===============================\n",
    "\n",
    "        self.lossyear_slider = widgets.IntSlider(\n",
    "            value=23,\n",
    "            min=1,\n",
    "            max=23,\n",
    "            step=1,\n",
    "            description='Loss year:',\n",
    "            continuous_update=False,\n",
    "            layout=Layout(width='95%')\n",
    "        )\n",
    "\n",
    "        self.lossyear_slider.observe(self.update_lossyear_layer, names='value')\n",
    "\n",
    "        # Progress bar\n",
    "        self.progress = widgets.IntProgress(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            description='Progress:',\n",
    "            bar_style='info',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=Layout(width='95%')\n",
    "        )\n",
    "\n",
    "        # Status label\n",
    "        self.status = widgets.HTML(\n",
    "            value=\"<h4>Status: <span style='color:blue'>Ready - Draw a region on the map</span></h4>\",\n",
    "            layout=Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        # Results display\n",
    "        self.results_label = widgets.HTML(\n",
    "            value=\"<h3>üìä Results</h3>\",\n",
    "            layout=Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        # Visualization button\n",
    "        self.viz_btn = widgets.Button(\n",
    "            description=\"üìà Visualize Results\",\n",
    "            button_style='info',\n",
    "            disabled=True,\n",
    "            icon='chart-bar',\n",
    "            layout=Layout(width='200px', height='40px')\n",
    "        )\n",
    "        self.viz_btn.on_click(self.visualize_results)\n",
    "\n",
    "        # Download results button\n",
    "        self.download_results_btn = widgets.Button(\n",
    "            description=\"üíæ Download GeoTIFFs\",\n",
    "            button_style='info',\n",
    "            disabled=True,\n",
    "            icon='file-download',\n",
    "            layout=Layout(width='200px', height='40px')\n",
    "        )\n",
    "        self.download_results_btn.on_click(self.download_results)\n",
    "\n",
    "        # Instructions\n",
    "        self.instructions = widgets.Accordion(children=[\n",
    "            widgets.HTML(\"\"\"\n",
    "            <div style=\"padding: 10px; font-size: 14px;\">\n",
    "            <h4>üìñ HOW TO USE:</h4>\n",
    "            <ol>\n",
    "                <li><strong>Draw a polygon</strong> on the map</li>\n",
    "                <li>System detects region automatically</li>\n",
    "                <li>Click <strong>\"Download Satellite Data\"</strong></li>\n",
    "                <li>Click <strong>\"Run Follow-up Land Use Prediction\"</strong></li>\n",
    "                <li>View results and download GeoTIFFs</li>\n",
    "            </ol>\n",
    "            <h4>üìä OUTPUT:</h4>\n",
    "            <ul>\n",
    "                <li><strong>Land Use Map</strong>: Predicted classes (GeoTIFF)</li>\n",
    "                <li><strong>Confidence Map</strong>: Prediction confidence (GeoTIFF)</li>\n",
    "                <li><strong>Visualizations</strong>: RGB, predictions, statistics</li>\n",
    "            </ul>\n",
    "            <h4>‚ö†Ô∏è NOTES:</h4>\n",
    "            <ul>\n",
    "                <li>Predictions only on deforested areas</li>\n",
    "                <li>Each region has specific model</li>\n",
    "                <li>Processing time: 1-5 minutes</li>\n",
    "                <li>Requires internet for data/model download</li>\n",
    "            </ul>\n",
    "            </div>\n",
    "            \"\"\")\n",
    "        ])\n",
    "        self.instructions.set_title(0, 'üìö Instructions')\n",
    "        self.instructions.selected_index = None\n",
    "\n",
    "    def _create_layout(self):\n",
    "        \"\"\"Arrange widgets in layout\"\"\"\n",
    "        button_row1 = HBox([\n",
    "            self.download_btn,\n",
    "            self.predict_btn,\n",
    "            self.clear_btn\n",
    "        ], layout=Layout(justify_content='center', margin='10px 0'))\n",
    "\n",
    "        button_row2 = HBox([\n",
    "            self.viz_btn,\n",
    "            self.download_results_btn\n",
    "        ], layout=Layout(justify_content='center', margin='10px 0'))\n",
    "\n",
    "        control_panel = VBox([\n",
    "            self.instructions,\n",
    "            self.region_label,\n",
    "            self.roi_label,\n",
    "            self.region_dropdown,\n",
    "            self.lossyear_slider,\n",
    "            button_row1,\n",
    "            self.progress,\n",
    "            self.status,\n",
    "            self.results_label,\n",
    "            button_row2\n",
    "            #self.output\n",
    "        ], layout=Layout(width='30%', padding='10px'))\n",
    "\n",
    "        self.main_layout = VBox([\n",
    "            HBox([\n",
    "                self.map,\n",
    "                control_panel\n",
    "            ], layout=Layout(width='100%')),\n",
    "\n",
    "            self.output   # ‚Üê visualizations now appear BELOW the map\n",
    "        ], layout=Layout(width='100%'))\n",
    "\n",
    "    def on_region_change(self, change):\n",
    "        \"\"\"Handle manual region selection\"\"\"\n",
    "        if change['new']:\n",
    "            self.region_name = change['new']\n",
    "            self.region_config = REGION_CONFIGS.get(self.region_name, {}).copy()\n",
    "\n",
    "            self.region_label.value = f\"\"\"\n",
    "            <h3>üåç Region: <span style='color:green'>{self.region_name} (Manual)</span></h3>\n",
    "            \"\"\"\n",
    "\n",
    "            if self.roi:\n",
    "                self.download_btn.disabled = False\n",
    "\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                print(f\"‚úì Region set to: {self.region_name}\")\n",
    "\n",
    "\n",
    "    def update_lossyear_layer(self, change):\n",
    "        \"\"\"Update forest loss year visualization\"\"\"\n",
    "        year = change['new']\n",
    "\n",
    "        #hansen = ee.Image('UMD/hansen/global_forest_change_2023_v1_11')\n",
    "        #lossyear = hansen.select('lossyear')\n",
    "\n",
    "        #filtered = lossyear.updateMask(lossyear.eq(year))\n",
    "        filtered = self.lossyear_img.updateMask(\n",
    "            self.lossyear_img.eq(year)\n",
    "        )\n",
    "\n",
    "        vis = {\n",
    "            'min': 1,\n",
    "            'max': 23,\n",
    "            'palette': ['red']\n",
    "        }\n",
    "\n",
    "\n",
    "        self.map.layers = self.map.layers[:3]  # keep basemap + base layers\n",
    "        #self.map.addLayer(\n",
    "        #        filtered,\n",
    "        #        vis,\n",
    "        #        f'Forest loss {2000 + year}',\n",
    "        #        shown=True\n",
    "        #    )\n",
    "\n",
    "\n",
    "\n",
    "    def download_data(self, b):\n",
    "        \"\"\"Download satellite data for ROI\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "\n",
    "            if not self.roi:\n",
    "                print(\"‚ùå Please draw a region on the map first\")\n",
    "                return\n",
    "\n",
    "            if not self.region_name:\n",
    "                print(\"‚ùå Could not detect region. Please select manually.\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                self.progress.value = 0\n",
    "                self.status.value = \"<h4>Status: <span style='color:orange'>Downloading satellite data...</span></h4>\"\n",
    "\n",
    "                print(f\"üì• Downloading data for {self.region_name}...\")\n",
    "\n",
    "                bbox = self.roi.buffer(500).bounds()\n",
    "                self.progress.value = 30\n",
    "\n",
    "                self.data_path = download_region_data(\n",
    "                    bbox,\n",
    "                    self.region_name,\n",
    "                    scale=10,\n",
    "                    output_dir='downloads'\n",
    "                )\n",
    "\n",
    "                self.progress.value = 60\n",
    "                print(f\"‚úì Data downloaded\")\n",
    "\n",
    "                print(f\"üß† Loading {self.region_name} model...\")\n",
    "                self.model_session, loaded_config = load_onnx_model(self.region_name)\n",
    "                self.region_config.update(loaded_config)\n",
    "\n",
    "                self.progress.value = 100\n",
    "                self.predict_btn.disabled = False\n",
    "\n",
    "                self.status.value = f\"\"\"\n",
    "                <h4>Status: <span style='color:green'>‚úì Data and model loaded</span></h4>\n",
    "                \"\"\"\n",
    "\n",
    "                print(\"‚úÖ Ready to run prediction\")\n",
    "\n",
    "            except Exception as e:\n",
    "                self.status.value = f\"<h4>Status: <span style='color:red'>Error: {str(e)[:100]}</span></h4>\"\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "    def run_prediction(self, b):\n",
    "        \"\"\"Run follow-up land use prediction\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "\n",
    "            if not self.data_path:\n",
    "                print(\"‚ùå Please download data first\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                self.progress.value = 0\n",
    "                self.status.value = \"<h4>Status: <span style='color:orange'>Running prediction...</span></h4>\"\n",
    "\n",
    "                print(f\"üß† Running prediction for {self.region_name}...\")\n",
    "                self.progress.value = 20\n",
    "\n",
    "                self.prediction_path, self.confidence_path, self.class_names = predict_land_use(\n",
    "                    self.model_session,\n",
    "                    self.region_config,\n",
    "                    self.data_path\n",
    "                )\n",
    "\n",
    "                self.progress.value = 80\n",
    "\n",
    "                with rasterio.open(self.prediction_path) as src:\n",
    "                    pred_data = src.read(1)\n",
    "                    #pred_data = reshape_as_image(pred_data)\n",
    "                    unique_classes = np.unique(pred_data[pred_data > 0])\n",
    "\n",
    "                self.progress.value = 100\n",
    "                self.viz_btn.disabled = False\n",
    "                self.download_results_btn.disabled = False\n",
    "\n",
    "                self.results_label.value = f\"\"\"\n",
    "                <h3>üìä Results - {self.region_name}</h3>\n",
    "                <p><strong>Classes found:</strong> {len(unique_classes)}</p>\n",
    "                <p><strong>Land use map:</strong> {os.path.basename(self.prediction_path)}</p>\n",
    "                <p><strong>Confidence map:</strong> {os.path.basename(self.confidence_path)}</p>\n",
    "                \"\"\"\n",
    "\n",
    "                self.status.value = f\"\"\"\n",
    "                <h4>Status: <span style='color:green'>‚úì Prediction complete!</span></h4>\n",
    "                \"\"\"\n",
    "\n",
    "                print(f\"‚úÖ Prediction complete!\")\n",
    "                print(f\"üìÅ Output files saved in 'predictions' directory\")\n",
    "\n",
    "            except Exception as e:\n",
    "                self.status.value = f\"<h4>Status: <span style='color:red'>Error: {str(e)[:100]}</span></h4>\"\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "    def visualize_results(self, b):\n",
    "        \"\"\"Visualize prediction results\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "\n",
    "            if not self.prediction_path:\n",
    "                print(\"‚ùå Please run prediction first\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                print(\"üìà Generating visualizations...\")\n",
    "                visualize_results(\n",
    "                    self.data_path,\n",
    "                    self.prediction_path,\n",
    "                    self.confidence_path,\n",
    "                    self.class_names,\n",
    "                    self.region_name\n",
    "                )\n",
    "\n",
    "                if self.class_names:\n",
    "                    legend_fig = create_legend(self.class_names, self.region_config.get('color_map', plt.cm.tab20))\n",
    "                    plt.show()\n",
    "                    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "\n",
    "                print(\"‚úÖ Visualizations generated!\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "    def download_results(self, b):\n",
    "        \"\"\"Provide download links for results\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "\n",
    "            if not self.prediction_path:\n",
    "                print(\"‚ùå No results to download\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                print(\"üíæ Download GeoTIFF files:\")\n",
    "                print(\"=\" * 50)\n",
    "\n",
    "                from IPython.display import FileLink, display\n",
    "\n",
    "                print(\"\\n1. Land Use Classification:\")\n",
    "                display(FileLink(self.prediction_path, result_html_prefix=\"üó∫Ô∏è \"))\n",
    "\n",
    "                print(\"\\n2. Prediction Confidence:\")\n",
    "                display(FileLink(self.confidence_path, result_html_prefix=\"üìä \"))\n",
    "\n",
    "                print(\"\\n3. Input Satellite Data:\")\n",
    "                display(FileLink(self.data_path, result_html_prefix=\"üõ∞Ô∏è \"))\n",
    "\n",
    "                print(\"\\n‚úÖ Files ready for download\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "    def clear_all(self, b):\n",
    "        \"\"\"Clear all selections and reset\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            print(\"üóëÔ∏è Clearing all data...\")\n",
    "\n",
    "        self.roi = None\n",
    "        self.region_name = None\n",
    "        self.region_config = {}\n",
    "        self.model_session = None\n",
    "        self.data_path = None\n",
    "        self.prediction_path = None\n",
    "        self.confidence_path = None\n",
    "        self.class_names = None\n",
    "\n",
    "        self.map.clear_draw()\n",
    "\n",
    "        self.region_label.value = \"<h3>üåç Region: <span style='color:red'>Not selected</span></h3>\"\n",
    "        self.roi_label.value = \"<h3>üó∫Ô∏è ROI: <span style='color:red'>Not drawn</span></h3>\"\n",
    "        self.region_dropdown.value = None\n",
    "        self.results_label.value = \"<h3>üìä Results</h3>\"\n",
    "\n",
    "        self.download_btn.disabled = True\n",
    "        self.predict_btn.disabled = True\n",
    "        self.viz_btn.disabled = True\n",
    "        self.download_results_btn.disabled = True\n",
    "\n",
    "        self.progress.value = 0\n",
    "        self.status.value = \"<h4>Status: <span style='color:blue'>Ready - Draw a region on the map</span></h4>\"\n",
    "\n",
    "        self._setup_draw_control()\n",
    "\n",
    "        print(\"‚úÖ All cleared! Ready for new analysis.\")\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display the interface\"\"\"\n",
    "        display(self.main_layout)\n",
    "\n",
    "    # Ensure layer control is added last\n",
    "\n",
    "\n",
    "\n",
    "print(\"‚úÖ Interactive interface defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VxHj4EVxbq_"
   },
   "source": [
    "# ## 11. LAUNCH THE APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "853eadc337de47f2b403144a0c2d262b",
      "e589148645dc423e8c058f1c524d58f5",
      "68cc5c9f76f84f54805337ac100887f0",
      "b1850c90aaf346d4b85eb0805f3e41c5",
      "0af8fd7f7a65438db460a7dd1cccc8dd",
      "93b63551db76480882d3da552fce8458",
      "d5710e22fed648af8736bec4aebb71ad",
      "1c8e8917993445208f03aee5d4c2a5a3",
      "d37d469db5ba4f77857864334933edc7",
      "890a2a99d2b742ffb1346e92a0796015",
      "fd5e520ef1064bfa8f56d2fe70ec69eb",
      "38f04a2594c74206a4db9837025eec2e",
      "03b8131b8d6e473789187be1e347eccb",
      "438bcddefea64959a32e70352c771fda",
      "fe50f74ac83f41d2a3314a31ddc5a85e",
      "2b83001f6c504ca098c942bf895711a2",
      "25b4c7f6e5014eb29bbd96849fa8c8b2",
      "25e496174f0240e5918ec8f9662ccc6b",
      "a5e0571e64434aeeafb064cc2bccf14f",
      "2dfeb7c815624a018ba2b0cd47c84e25",
      "1543dc1e538f44b788db143e92617682",
      "f5c137adacf648dc95ec1f8c14c193a0",
      "4b7154b306ad472c8872e99cf29a86be",
      "0b75f774494f4fa99e5dd90282fac309",
      "b0dfd6f620424290ae27fcce5b3ec548",
      "073bbc96392245c0bcee71b197807762",
      "3ea8bfdbf2d7415c9b1868465b4e3193",
      "dfbf66eae2024ea2acddf3d201c95008",
      "29cba5e428154d5891a009340b700abe",
      "adccbe0c31c34990a675d0c9bdb86904",
      "f973b39bc07c4f59b3bd89a5dfa64b66",
      "69446d15c76c4863ade99ef44da0a09e",
      "094e9343e0814b51bc738569296655ed",
      "eadd50b713234c7397862860e845d885",
      "6104826151304f1bacd2c93aaf612d17",
      "6548bb3771de409997500ad523a35d64",
      "a6502aa182154b9c9a2a259c0e4947f3",
      "a4471ab93b0a49acbc254d61c37ece29",
      "a9cba536c3454425a7269e1965724887",
      "219376be105f4f73ad95989ccc684a3e",
      "31d8e4f146fe492da36c5594c6a296ff",
      "79d7a46f829b480098047db6d99605ba",
      "558f36377dd748de94ed3ff91b4730d8",
      "c1d5a7fa5c19448a8b4e1c38545affdc",
      "92b37e7e4ccb49e7b99962e443dc5741",
      "020b7baa25864019a28b8d4fdae79bc7",
      "4afa24183fd84bcfbf48ab780c6cb175",
      "f99697049a04452cb7a3b0bd0130136b",
      "1cb8c269bf084f3db4a35d88bc1c944c",
      "46c9dc4851134c3294e51e553db91363",
      "1e08475a389a4c6587633c5284b3308b",
      "f8fdaff0da79420b83af1fc32432d264",
      "93b7edcbcee440a9b768e6ae07db36e0",
      "1dbf9f6bb69c4b6a97ef3f7b6f384351",
      "c21f95d2f5994996ab7373c2e87c35f9",
      "0cfc06feebdb448db1e0224d42ad3650",
      "0d35f4e2e9a24dbc946d363d60c4fb4a",
      "57e72cdc86ba4e8e8a9644f99b7e9ab6",
      "58f0cfe2b2b44fee89d99611f4ef9fe1",
      "56074a9e2206457da6e5ed74620091f8",
      "05dc8db3e47d4349bd47f4c62ad5f073",
      "dd42d0291f9b4c86b5f4a35a9fe8e0fe",
      "dc6bbae4595c4574b81666b3d7608160",
      "a66f1257469b470092b6a0b1eb194f7b",
      "2104b60ffa3442869395d8ea9b805ce1",
      "b55a1887af4142e3a4056129bdca23b7",
      "c803dab5207d4fac815a3fa138a65fdc",
      "271dd669707d40738ceaa5287053e723",
      "a5cd6f60a81941f2a5cadd1348bce172",
      "f07695611c674bebaa911200dcf8a72a",
      "c421f733e132441cb13b7a9ccc1e8d4b",
      "3329cdedb8744a99b22eb1cd539f2008",
      "9a29fc96bcbb43ffb786be52660b24a1",
      "1a390f56cc884f8d9c698e0145b84420",
      "510be3d659d74559b64c441bd39b568d"
     ]
    },
    "id": "6HzgjvFivvOI",
    "outputId": "12153a43-614a-4e20-f663-0bbb2e70ba00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üåç POST-DEFORESTATION LAND USE PREDICTION SYSTEM\n",
      "================================================================================\n",
      "Version: 1.0\n",
      "Author: Your Name/Organization\n",
      "Date: 2024\n",
      "\n",
      "SUPPORTED REGIONS:\n",
      "- Africa (25 land use classes)\n",
      "- Southeast Asia (24 land use classes)\n",
      "- Latin America (22 land use classes)\n",
      "\n",
      "INSTRUCTIONS:\n",
      "1. Draw a polygon on the map within a supported region\n",
      "2. Click \"Download Satellite Data\" to fetch Sentinel-1/2 data\n",
      "3. Click \"Run Follow-up Land Use Prediction\" to classify deforestation areas\n",
      "4. Visualize results and download GeoTIFF files\n",
      "\n",
      "OUTPUT:\n",
      "- Follow-up land use classification map (GeoTIFF)\n",
      "- Prediction confidence map (GeoTIFF)\n",
      "- Interactive visualizations\n",
      "- Class legend and statistics\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853eadc337de47f2b403144a0c2d262b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Map(center=[0, 0], controls=(MapDrawControl(marker={'shapeOptions': {'color': '#‚Ä¶"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîß TROUBLESHOOTING GUIDE\n",
      "================================================================================\n",
      "\n",
      "COMMON ISSUES:\n",
      "\n",
      "1. \"Earth Engine not authenticated\"\n",
      "   - Run the authentication cell (Section 1)\n",
      "   - Follow the prompts to authorize\n",
      "\n",
      "2. \"Model not found\" error\n",
      "   - Check internet connection\n",
      "   - Manual download: https://huggingface.co/datasets/Masolele/deforestwatch-models\n",
      "   - Place .onnx files in 'models/' directory\n",
      "\n",
      "3. Slow download/prediction\n",
      "   - Use smaller ROI (under 100 km¬≤ for testing)\n",
      "   - 30m resolution is sufficient for most applications\n",
      "\n",
      "4. No results in prediction\n",
      "   - The area might not have deforestation (loss = 0)\n",
      "   - Try a different location with known deforestation\n",
      "\n",
      "5. Visualization errors\n",
      "   - Ensure prediction ran successfully first\n",
      "   - Check if output files exist in 'predictions/' directory\n",
      "\n",
      "GETTING HELP:\n",
      "- Check console output for error messages\n",
      "- Ensure all packages are installed (Section 1)\n",
      "- Models require ~50MB each (download once)\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "\n",
    "\n",
    "# %%\n",
    "print(\"\"\"\n",
    "================================================================================\n",
    "üåç POST-DEFORESTATION LAND USE PREDICTION SYSTEM\n",
    "================================================================================\n",
    "Version: 1.0\n",
    "Author: Your Name/Organization\n",
    "Date: 2024\n",
    "\n",
    "SUPPORTED REGIONS:\n",
    "- Africa (25 land use classes)\n",
    "- Southeast Asia (24 land use classes)\n",
    "- Latin America (22 land use classes)\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Draw a polygon on the map within a supported region\n",
    "2. Click \"Download Satellite Data\" to fetch Sentinel-1/2 data\n",
    "3. Click \"Run Follow-up Land Use Prediction\" to classify deforestation areas\n",
    "4. Visualize results and download GeoTIFF files\n",
    "\n",
    "OUTPUT:\n",
    "- Follow-up land use classification map (GeoTIFF)\n",
    "- Prediction confidence map (GeoTIFF)\n",
    "- Interactive visualizations\n",
    "- Class legend and statistics\n",
    "================================================================================\n",
    "\"\"\")\n",
    "\n",
    "# Create and display the predictor\n",
    "predictor = DeforestationPredictor()\n",
    "predictor.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz1o1SknAxzd"
   },
   "source": [
    "# ## 12. TROUBLESHOOTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCS-L0qqACf8"
   },
   "source": [
    "================================================================================\n",
    "üîß TROUBLESHOOTING GUIDE\n",
    "================================================================================\n",
    "\n",
    "COMMON ISSUES:\n",
    "\n",
    "1. \"Earth Engine not authenticated\"\n",
    "   - Run the authentication cell (Section 1)\n",
    "   - Follow the prompts to authorize\n",
    "\n",
    "2. \"Model not found\" error\n",
    "   - Check internet connection\n",
    "   - Manual download: https://huggingface.co/datasets/Masolele/deforestwatch-models\n",
    "   - Place .onnx files in 'models/' directory\n",
    "\n",
    "3. Slow download/prediction\n",
    "   - Use smaller ROI (under 100 km¬≤ for testing)\n",
    "   - 10m resolution is sufficient for most applications\n",
    "\n",
    "4. No results in prediction\n",
    "   - The area might not have deforestation (loss = 0)\n",
    "   - Try a different location with known deforestation\n",
    "\n",
    "5. Visualization errors\n",
    "   - Ensure prediction ran successfully first\n",
    "   - Check if output files exist in 'predictions/' directory\n",
    "\n",
    "GETTING HELP:\n",
    "- Check console output for error messages\n",
    "- Ensure all packages are installed (Section 1)\n",
    "- Models require ~50MB each (download once)\n",
    "================================================================================\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
